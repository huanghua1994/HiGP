{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to use the easiest interface in HiGP for regression problems.\n",
    "\n",
    "We use a simple example to show the basic usage of HiGP. In this example, we train a RBF (Gaussian) kernel GP for a one-dimensional function. We will be modeling the function\n",
    "\n",
    "```math\n",
    "y = 0.2 \\sin(3 \\pi x) \\exp(4x) + \\epsilon, \\ \n",
    "\\epsilon \\sim \\mathcal{N}(0, 0.09)\n",
    "```\n",
    "\n",
    "The regression can be calculated by `higp_py.ezgpr_torch()`. By default, it is in single precision.\n",
    "\n",
    "In this example, we use the RBF (Gaussian) kernel function in the form\n",
    "$$\n",
    "\\mathcal{K}(x,y)=f^2 \\exp\\left(\\frac{-\\|x - y\\|_2^2}{2 l^2}\\right).\n",
    "$$\n",
    "\n",
    "As we hope to make the actual parameters in $(0,\\infty)$, we train our parameters in $\\mathbb{R}$ and apply the softplus transformation to get the actual parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import torch\n",
    "import higp\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the dataset\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "n_train = 200\n",
    "n_test  = 1000\n",
    "train_x = np.linspace(0, 1, n_train)\n",
    "train_y = 0.2 * np.sin(3 * math.pi * train_x) * np.exp(4 * train_x) \n",
    "train_y += np.random.randn(train_x.size) * math.sqrt(0.09)\n",
    "test_x  = np.sort(np.random.rand(n_test))\n",
    "test_y  = 0.2 * np.sin(3 * math.pi * test_x) * np.exp(4 * test_x)\n",
    "test_y += np.random.randn(test_x.size) * math.sqrt(0.09)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first visualize the training set and testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[0].plot(train_x, train_y, 'b.')\n",
    "axs[0].set_title('Training Data')\n",
    "axs[0].set_xlabel('x')\n",
    "axs[0].set_ylabel('y')\n",
    "axs[1].plot(test_x, test_y, 'b.')\n",
    "axs[1].set_title('Testing Data')\n",
    "axs[1].set_xlabel('x')\n",
    "axs[1].set_ylabel('y')\n",
    "plt.show()\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we directly call the simplest interface.\n",
    "\n",
    "We use a learning rate 0.1 by setting `adam_lr = 0.1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 200 training / 1000 test data points\n",
      "Data dimension: 1\n",
      "Iteration (max 100), Elapsed time (sec), Loss, Hyperparameters (l, s, f, before nnt)\n",
      "Change random seed to 42\n",
      "Setting up GPR problem with 200 samples and 1 features\n",
      "Init gpr problem done\n",
      "====================================\n",
      "Creating GPR problem\n",
      "Data type: float\n",
      "Kernel type: Gaussian\n",
      "Transform type: softplus\n",
      "Using preconditioned GP, kernel matrix form: dense / fall back to on-the-fly\n",
      "AFN preconditioner parameters: rank 50, lfil 0\n",
      "LanQ parameters: niter 10, nvec 10\n",
      "====================================\n",
      "1, 0.03, 2.77837, -0.100, 0.100, 0.100\n",
      "2, 0.05, 2.57451, -0.200, 0.199, 0.199\n",
      "3, 0.07, 2.39973, -0.299, 0.296, 0.297\n",
      "4, 0.09, 2.25161, -0.397, 0.391, 0.393\n",
      "5, 0.11, 2.12608, -0.495, 0.483, 0.486\n",
      "6, 0.13, 2.01797, -0.592, 0.572, 0.577\n",
      "7, 0.15, 1.92167, -0.689, 0.656, 0.664\n",
      "8, 0.17, 1.83194, -0.786, 0.734, 0.749\n",
      "9, 0.19, 1.74487, -0.884, 0.807, 0.832\n",
      "10, 0.21, 1.65900, -0.982, 0.872, 0.913\n",
      "11, 0.23, 1.57577, -1.081, 0.928, 0.993\n",
      "12, 0.25, 1.49824, -1.180, 0.975, 1.072\n",
      "13, 0.27, 1.42898, -1.279, 1.013, 1.148\n",
      "14, 0.29, 1.36977, -1.376, 1.041, 1.223\n",
      "15, 0.31, 1.32205, -1.471, 1.060, 1.295\n",
      "16, 0.33, 1.28572, -1.562, 1.070, 1.364\n",
      "17, 0.35, 1.25862, -1.649, 1.071, 1.430\n",
      "18, 0.37, 1.23801, -1.731, 1.065, 1.492\n",
      "19, 0.39, 1.22170, -1.808, 1.053, 1.551\n",
      "20, 0.41, 1.20822, -1.880, 1.033, 1.606\n",
      "21, 0.43, 1.19660, -1.946, 1.008, 1.658\n",
      "22, 0.45, 1.18608, -2.008, 0.977, 1.706\n",
      "23, 0.47, 1.17606, -2.064, 0.941, 1.750\n",
      "24, 0.50, 1.16610, -2.115, 0.901, 1.791\n",
      "25, 0.52, 1.15587, -2.161, 0.857, 1.829\n",
      "26, 0.54, 1.14511, -2.203, 0.809, 1.865\n",
      "27, 0.56, 1.13367, -2.241, 0.757, 1.897\n",
      "28, 0.58, 1.12143, -2.274, 0.703, 1.926\n",
      "29, 0.60, 1.10833, -2.303, 0.645, 1.953\n",
      "30, 0.62, 1.09432, -2.329, 0.584, 1.978\n",
      "31, 0.64, 1.07937, -2.352, 0.521, 2.000\n",
      "32, 0.66, 1.06347, -2.371, 0.455, 2.020\n",
      "33, 0.68, 1.04660, -2.387, 0.387, 2.038\n",
      "34, 0.70, 1.02876, -2.400, 0.317, 2.055\n",
      "35, 0.72, 1.00994, -2.410, 0.245, 2.070\n",
      "36, 0.74, 0.99016, -2.418, 0.171, 2.083\n",
      "37, 0.76, 0.96941, -2.424, 0.095, 2.094\n",
      "38, 0.78, 0.94773, -2.427, 0.017, 2.104\n",
      "39, 0.80, 0.92513, -2.428, -0.063, 2.113\n",
      "40, 0.82, 0.90165, -2.427, -0.144, 2.121\n",
      "41, 0.84, 0.87732, -2.425, -0.226, 2.127\n",
      "42, 0.86, 0.85220, -2.420, -0.310, 2.133\n",
      "43, 0.88, 0.82633, -2.414, -0.396, 2.137\n",
      "44, 0.90, 0.79980, -2.406, -0.482, 2.141\n",
      "45, 0.92, 0.77268, -2.397, -0.570, 2.144\n",
      "46, 0.94, 0.74506, -2.387, -0.659, 2.147\n",
      "47, 0.96, 0.71704, -2.376, -0.748, 2.148\n",
      "48, 0.99, 0.68874, -2.363, -0.839, 2.150\n",
      "49, 1.01, 0.66027, -2.350, -0.930, 2.150\n",
      "50, 1.03, 0.63179, -2.336, -1.021, 2.151\n",
      "51, 1.05, 0.60344, -2.321, -1.113, 2.151\n",
      "52, 1.07, 0.57539, -2.305, -1.205, 2.151\n",
      "53, 1.09, 0.54780, -2.289, -1.297, 2.150\n",
      "54, 1.11, 0.52086, -2.273, -1.389, 2.150\n",
      "55, 1.13, 0.49477, -2.256, -1.480, 2.149\n",
      "56, 1.15, 0.46970, -2.239, -1.571, 2.149\n",
      "57, 1.17, 0.44587, -2.222, -1.661, 2.149\n",
      "58, 1.19, 0.42347, -2.205, -1.750, 2.149\n",
      "59, 1.21, 0.40268, -2.188, -1.837, 2.149\n",
      "60, 1.23, 0.38368, -2.172, -1.922, 2.149\n",
      "61, 1.25, 0.36662, -2.156, -2.005, 2.150\n",
      "62, 1.27, 0.35164, -2.140, -2.086, 2.151\n",
      "63, 1.29, 0.33884, -2.125, -2.163, 2.153\n",
      "64, 1.31, 0.32826, -2.111, -2.237, 2.156\n",
      "65, 1.33, 0.31989, -2.097, -2.307, 2.159\n",
      "66, 1.35, 0.31363, -2.085, -2.373, 2.162\n",
      "67, 1.37, 0.30937, -2.073, -2.434, 2.167\n",
      "68, 1.39, 0.30690, -2.063, -2.489, 2.172\n",
      "69, 1.41, 0.30596, -2.053, -2.540, 2.178\n",
      "70, 1.43, 0.30626, -2.045, -2.584, 2.184\n",
      "71, 1.45, 0.30748, -2.038, -2.623, 2.192\n",
      "72, 1.48, 0.30929, -2.032, -2.655, 2.200\n",
      "73, 1.50, 0.31135, -2.028, -2.681, 2.209\n",
      "74, 1.52, 0.31337, -2.024, -2.702, 2.219\n",
      "75, 1.54, 0.31512, -2.022, -2.716, 2.229\n",
      "76, 1.56, 0.31644, -2.020, -2.725, 2.240\n",
      "77, 1.58, 0.31719, -2.020, -2.728, 2.251\n",
      "78, 1.60, 0.31736, -2.020, -2.726, 2.263\n",
      "79, 1.62, 0.31696, -2.021, -2.720, 2.276\n",
      "80, 1.64, 0.31608, -2.022, -2.710, 2.288\n",
      "81, 1.66, 0.31480, -2.024, -2.696, 2.301\n",
      "82, 1.69, 0.31327, -2.026, -2.680, 2.314\n",
      "83, 1.71, 0.31160, -2.029, -2.662, 2.328\n",
      "84, 1.73, 0.30991, -2.031, -2.642, 2.341\n",
      "85, 1.75, 0.30830, -2.034, -2.620, 2.354\n",
      "86, 1.77, 0.30685, -2.036, -2.599, 2.367\n",
      "87, 1.79, 0.30561, -2.039, -2.577, 2.380\n",
      "88, 1.81, 0.30461, -2.041, -2.555, 2.393\n",
      "89, 1.83, 0.30385, -2.042, -2.534, 2.406\n",
      "90, 1.85, 0.30332, -2.044, -2.514, 2.419\n",
      "91, 1.87, 0.30302, -2.045, -2.495, 2.431\n",
      "92, 1.89, 0.30288, -2.046, -2.478, 2.443\n",
      "93, 1.91, 0.30289, -2.046, -2.462, 2.455\n",
      "94, 1.93, 0.30300, -2.046, -2.448, 2.466\n",
      "95, 1.96, 0.30318, -2.045, -2.436, 2.477\n",
      "96, 1.98, 0.30339, -2.044, -2.426, 2.488\n",
      "97, 2.00, 0.30360, -2.043, -2.417, 2.499\n",
      "98, 2.02, 0.30378, -2.041, -2.410, 2.509\n",
      "99, 2.04, 0.30393, -2.039, -2.405, 2.519\n",
      "100, 2.06, 0.30402, -2.037, -2.402, 2.529\n",
      "Training time: 2.08636\n",
      "====================================\n",
      "Running GPR prediction\n",
      "Data type: float\n",
      "Kernel type: Gaussian\n",
      "Transform type: softplus\n",
      "Using preconditioned GP, kernel matrix form: dense / fall back to on-the-fly\n",
      "Prediction time: 0.017467\n",
      "RMSE: 0.316146\n",
      "\n",
      "AFN preconditioner parameters: rank 50, lfil 0\n",
      "PCG parameters: niter 500, tol 1e-05\n",
      "====================================\n",
      "Dealloc gpr problem done\n"
     ]
    }
   ],
   "source": [
    "pred = higp.ezgpr_torch(train_x, train_y, test_x, test_y, adam_lr=0.1, adam_maxits=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the prediction results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "plt.plot(test_x, test_y, 'ro', markersize=2)\n",
    "pred_y = pred.prediction_mean\n",
    "std_y = pred.prediction_stddev\n",
    "plt.plot(test_x, pred_y, 'b-')\n",
    "plt.fill_between(test_x, pred_y - 1.96 * std_y, pred_y + 1.96 * std_y, alpha=0.5)\n",
    "plt.title('Testing label and prediction')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend(['Testing label', 'Prediction Mean', '95% Confidence'], loc='upper center')\n",
    "plt.show()\n",
    "plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "higp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
