{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to use the general interface in HiGP for regression problems.\n",
    "\n",
    "In this test, we will use the 3D Road dataset at \"https://archive.ics.uci.edu/ml/machine-learning-databases/00246/3D_spatial_network.txt\". \n",
    "\n",
    "We random sample 30000 points for training and use 100 points for testing for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import higp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is a large (> 20000 training points) and low-dimensional (2D or 3D) data set, HiGP can use the $\\mathcal{H}^2$ matrix for faster calculation. The $\\mathcal{H}^2$ matrix requires a higher working precision, so we use float64 instead of float32 in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_dtype = np.float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the dataset, Scale features to $[-1, 1]$ and normalize labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/00246/3D_spatial_network.txt\", sep=',', header=None)\n",
    "data_array = df.values[:, 1:]\n",
    "all_x = data_array[:, 1:3]\n",
    "all_y = data_array[:, -1]\n",
    "\n",
    "# Scale features and normalize labels\n",
    "all_x_max = np.max(all_x, 0)\n",
    "all_x_min = np.min(all_x, 0)\n",
    "all_x = 2.0 * (all_x - all_x_min[np.newaxis, :]) / (all_x_max[np.newaxis, :] - all_x_min[np.newaxis, :]) - 1.0\n",
    "all_y = (all_y - np.mean(all_y)) / np.std(all_y)\n",
    "\n",
    "# Randomly select a subset of the data\n",
    "n_all = all_x.shape[0]\n",
    "n_train = 30000\n",
    "n_test = 100\n",
    "n_sample = n_train + n_test\n",
    "\n",
    "sample_array = np.random.choice(n_all, n_sample, replace = False)\n",
    "\n",
    "train_x = np.ascontiguousarray(all_x[sample_array[:n_train], :].T).astype(np_dtype)\n",
    "train_y = np.ascontiguousarray(all_y[sample_array[:n_train]]).astype(np_dtype)\n",
    "test_x = np.ascontiguousarray(all_x[sample_array[n_train:], :].T).astype(np_dtype)\n",
    "test_y = np.ascontiguousarray(all_y[sample_array[n_train:]]).astype(np_dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember to use the `ascontiguousarray()` method in NumPy to guarantee that `train_x, train_y, test_x, test_y` are stored contiguously.\n",
    "\n",
    "Now let's check the shapes of these four arrays. We can see that each data point is stored in one column in `train_x` and `test_x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_x :  (2, 30000)\n",
      "Shape of train_y :  (30000,)\n",
      "Shape of test_x :  (2, 100)\n",
      "Shape of test_y :  (100,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of train_x : \", train_x.shape)\n",
    "print(\"Shape of train_y : \", train_y.shape)\n",
    "print(\"Shape of test_x : \", test_x.shape)\n",
    "print(\"Shape of test_y : \", test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a GP regression problem model and a PyTorch Adam optimizer. \n",
    "\n",
    "By default, HiGP uses the $\\mathcal{H}^2$ matrix if possible (`mvtype = 0`). If you want to disable the use of the $\\mathcal{H}^2$ matrix, set `mvtype = 1`. For more information about the parameter `mvtype`, please refer to the user manual. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_dtype = torch.float32 if np_dtype == np.float32 else torch.float64\n",
    "gprproblem = higp.gprproblem.setup(data = train_x, label = train_y, kernel_type = 1, mvtype = 0)\n",
    "model = higp.GPRModel(gprproblem, dtype = torch_dtype)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run 20 steps of Adam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration (max 20), Elapsed time (sec), Loss, Hyperparameters (l, s, f, before nnt)\n",
      "1, 4.91, 0.73834, 0.050, -0.050, 0.050\n",
      "2, 9.73, 0.72011, 0.100, -0.100, 0.100\n",
      "3, 14.51, 0.70171, 0.149, -0.150, 0.150\n",
      "4, 19.19, 0.68327, 0.198, -0.198, 0.199\n",
      "5, 23.87, 0.66518, 0.246, -0.236, 0.248\n",
      "6, 28.55, 0.65058, 0.292, -0.278, 0.297\n",
      "7, 33.30, 0.63468, 0.338, -0.318, 0.345\n",
      "8, 37.95, 0.61919, 0.382, -0.351, 0.393\n",
      "9, 42.80, 0.60648, 0.425, -0.377, 0.441\n",
      "10, 47.70, 0.59638, 0.466, -0.401, 0.488\n",
      "11, 52.59, 0.58670, 0.506, -0.427, 0.534\n",
      "12, 57.16, 0.57644, 0.544, -0.454, 0.580\n",
      "13, 62.03, 0.56583, 0.580, -0.481, 0.625\n",
      "14, 66.82, 0.55535, 0.615, -0.507, 0.669\n",
      "15, 71.64, 0.54492, 0.648, -0.534, 0.713\n",
      "16, 76.44, 0.53407, 0.679, -0.562, 0.756\n",
      "17, 81.37, 0.52286, 0.709, -0.593, 0.799\n",
      "18, 86.08, 0.51017, 0.738, -0.625, 0.840\n",
      "19, 90.77, 0.49736, 0.765, -0.658, 0.881\n",
      "20, 95.63, 0.48369, 0.792, -0.692, 0.922\n"
     ]
    }
   ],
   "source": [
    "loss_history, param_histpry = higp.gpr_torch_minimize(model, optimizer, maxits = 20, print_info = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run predictions with the initial parameters and the trained parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred0 = higp.gpr_prediction(data_train = train_x,\n",
    "                            label_train = train_y,\n",
    "                            data_prediction = test_x,\n",
    "                            kernel_type = 1,\n",
    "                            pyparams = np.hstack((0.0, 0.0, 0.0)))\n",
    "\n",
    "Pred = higp.gpr_prediction(data_train = train_x,\n",
    "                           label_train = train_y,\n",
    "                           data_prediction = test_x,\n",
    "                           kernel_type = 1,\n",
    "                           pyparams = model.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let us check the root mean squared error (RMSE) of the predition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE (before training): 0.0178134, RMSE (after training): 0.00791506\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rmse0 = np.linalg.norm(Pred0[0] - test_y) / np.sqrt(float(n_sample-n_train))\n",
    "rmse = np.linalg.norm(Pred[0] - test_y) / np.sqrt(float(n_sample-n_train))\n",
    "print(\"RMSE (before training): %g, RMSE (after training): %g\\n\" % (rmse0, rmse))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
